% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluateClassificationModel.R
\name{evaluateClassificationModel}
\alias{evaluateClassificationModel}
\title{Evaluate binary classification models.}
\usage{
evaluateClassificationModel(actual, pred_prob, cutoff = 0.5)
}
\arguments{
\item{actual}{Vector of actual binary classes being predicted (y).}

\item{pred_prob}{Vector of predicted probabilities by the model (y-hat).}

\item{cutoff}{Cutoff threshold to be set. Default value is 0.5.}
}
\value{
None
}
\description{
Evaluate binary classification model outputs based on the predicted probabilities and actual values.
For evaluation purposes, the Confusion Matrix, ROC Curve, and AUC are returned.
}
\examples{
evaluateClassificationModel(data_df$Actual, data_df$Predicted_Probabilities)

}
